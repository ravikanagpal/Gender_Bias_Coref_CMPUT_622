{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClarknManning_neuralcoref.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igpDu_oHTNrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bf3428-070c-4fdd-b1d6-2878f1a11fe5"
      },
      "source": [
        "!git clone https://github.com/ravikanagpal/Gender_Bias_Coref_CMPUT_622"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Gender_Bias_Coref_CMPUT_622'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 61 (delta 14), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDbhAe0TKuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802d31bb-279a-42ac-f8c3-eb83e47b625a"
      },
      "source": [
        "!pip install -q neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 368 kB 10.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 42.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 76.4 MB/s \n",
            "\u001b[?25h    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3XfhlfXTRTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c03f5f7-5e7e-4931-a3fd-1307af23c463"
      },
      "source": [
        "!pip install -q -U spacy==2.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 27.7 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 42.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 356 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 38.7 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTo47VutTT43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5a5517-1dfe-4ee7-a3fd-fa90018d6adc"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 6.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074431 sha256=a409d510a666604c485b3dbe2ca68dab860853c549eef8966e17709cef78e922\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x1bwcb0n/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTSFCuDUTXC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53adcc5-46f0-49d7-c726-2650819dd062"
      },
      "source": [
        "import json, random\n",
        "from tqdm.notebook import tqdm\n",
        "from urllib.parse import quote\n",
        "\n",
        "# Load your usual SpaCy model (one of SpaCy English models)\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add neural coref to SpaCy's pipe\n",
        "import neuralcoref\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40155833/40155833 [00:01<00:00, 26136661.56B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f9bdad2db90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj9zImVZgH-3"
      },
      "source": [
        "# parse each sentence and predict pronoun\n",
        "import pandas as pd\n",
        "\n",
        "data_gold = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/gold_BUG.csv\")\n",
        "data_full = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/full_BUG.csv\")\n",
        "data_balanced = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/balanced_BUG.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeQmGGCSLwhj"
      },
      "source": [
        "# saving the results in the csv format\n",
        "def save_results(results, resultfile = \"/content/Gender_Bias_Coref_CMPUT_622/output/neuralcoref.csv\"):\n",
        "    column_names = [\"predicted gender\", \"sentence text\", \"profession\", \"gender\",\"stereotype\", \"predicted gender\", \"predicted mentions\", \"Prediction\"]\n",
        "    df = pd.DataFrame(results, columns=column_names)\n",
        "    # storing the results to csv file\n",
        "    df.to_csv(resultfile, index=False)\n",
        "    return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vFWVEXaqkBp"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGQj_6qJQz3N"
      },
      "source": [
        "# This function finds coreferences clusters and check its span corresponding to occupation and gender index to get model accuracy\n",
        "def evaluate(data, nlp):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "  records = []\n",
        "  for index, row in data.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              flag = False\n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  flag = True\n",
        "              records.append((row['predicted gender'], row['sentence_text'], row['profession'], row['g'], row['stereotype'], main, cluster.mentions, flag))\n",
        "  save_results(records)\n",
        "  print(total_count)            \n",
        "  return true_count/ total_count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCDk6KMRAhm",
        "outputId": "9be26b68-bd55-4d0b-ad8d-fa540180c96b"
      },
      "source": [
        "# check model accuracy on gold dataset\n",
        "print(evaluate(data_gold, nlp))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719\n",
            "0.4816753926701571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3xtBviRq6h"
      },
      "source": [
        "#This function is used to calculate female vs male accuracy i.e. fairness metric delta-g\n",
        "def evaluate_gender(data, nlp, gender):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "\n",
        "  data_new = data.drop(data[(data['predicted gender'] != gender)].index)    \n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              \n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  \n",
        "              \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiIR2xpUSCLw",
        "outputId": "255e11d5-79f3-485a-983c-b2777eda87ba"
      },
      "source": [
        "acc_male = evaluate_gender(data_gold, nlp, 'Male')\n",
        "acc_female = evaluate_gender(data_gold, nlp, 'Female')\n",
        "delta_g = acc_male - acc_female\n",
        "print(delta_g)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1336\n",
            "383\n",
            "0.025134456934694627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz09SKTDDmsM"
      },
      "source": [
        "# use this metric to calculate stereotype bias of the model\n",
        "def evaluate_stereotype(data, nlp, stereotype):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        " \n",
        "  data_new = data.drop(data[(data['stereotype'] != stereotype)].index)\n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              \n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  \n",
        "              \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idcc1ZMzBAEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6313ef1-ea67-4700-aa39-d59c9e202ba0"
      },
      "source": [
        "acc_antistereo = evaluate_stereotype(data_gold, nlp, -1)\n",
        "acc_stereo = evaluate_stereotype(data_gold, nlp, 1)\n",
        "delta_s = acc_stereo - acc_antistereo\n",
        "print(delta_s)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n",
            "864\n",
            "-0.04298941798941802\n"
          ]
        }
      ]
    }
  ]
}