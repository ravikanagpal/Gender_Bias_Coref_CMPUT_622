{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClarknManning_neuralcoref.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4hTLUlk63b2e"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igpDu_oHTNrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf28a1b4-e6e1-4e49-aabf-840e55278ec7"
      },
      "source": [
        "!git clone https://github.com/ravikanagpal/Gender_Bias_Coref_CMPUT_622"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Gender_Bias_Coref_CMPUT_622'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDbhAe0TKuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07cadec-ce27-4ec0-ccb5-d7eee6bb5900"
      },
      "source": [
        "!pip install -q neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 368 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 36.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.4 MB/s \n",
            "\u001b[?25h    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3XfhlfXTRTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea7d596-dfb3-484f-bf8d-ab7393a83a53"
      },
      "source": [
        "!pip install -q -U spacy==2.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 27.7 MB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 34.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 340 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 33.4 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTo47VutTT43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a781d2e-e566-4f49-c50d-7468ddef715b"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074431 sha256=5771aadc51d19ff34d18cbcea3e5c1e0c75a668ba1f562a66de48fab159e4283\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0rz2z7m5/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTSFCuDUTXC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573104b0-91b5-4f8e-959d-c4f91945f777"
      },
      "source": [
        "import json, random\n",
        "from tqdm.notebook import tqdm\n",
        "from urllib.parse import quote\n",
        "\n",
        "# Load your usual SpaCy model (one of SpaCy English models)\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add neural coref to SpaCy's pipe\n",
        "import neuralcoref\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40155833/40155833 [00:01<00:00, 30237531.35B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f629c814b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj9zImVZgH-3"
      },
      "source": [
        "# parse each sentence and predict pronoun\n",
        "import pandas as pd\n",
        "\n",
        "data_gold = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/gold_BUG.csv\")\n",
        "data_full = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/full_BUG.csv\")\n",
        "data_balanced = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/balanced_BUG.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmBh0vK2NrHO"
      },
      "source": [
        "def is_inside(offset, span):\n",
        "    return offset >= span[0] and offset <= span[1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vFWVEXaqkBp"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGQj_6qJQz3N"
      },
      "source": [
        "# This function finds coreferences clusters and check its span corresponding to occupation and gender index to get model accuracy\n",
        "def evaluate(data, nlp):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "  tp = 0 \n",
        "  tn = 0 \n",
        "  fp = 0 \n",
        "  fn = 0 \n",
        "  for index, row in data.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              if is_inside(row['profession_first_index'], main_span) and \\\n",
        "                      np.any([is_inside(row['g_first_index'], s) for s in mentions_spans]):\n",
        "                  true_count +=1  \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCDk6KMRAhm",
        "outputId": "a7fee5a2-4f94-4fe4-c3b7-a5c0cb99743e"
      },
      "source": [
        "# check model accuracy on gold dataset\n",
        "print(evaluate(data_gold, nlp))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719\n",
            "0.4537521815008726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3xtBviRq6h"
      },
      "source": [
        "#This function is used to calculate female vs male accuracy i.e. fairness metric delta-g\n",
        "def evaluate_gender(data, nlp, gender):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "  tp = 0 \n",
        "  tn = 0 \n",
        "  fp = 0 \n",
        "  fn = 0 \n",
        "  data_new = data.drop(data[(data['predicted gender'] != gender)].index)    \n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              if is_inside(row['profession_first_index'], main_span) and \\\n",
        "                      np.any([is_inside(row['g_first_index'], s) for s in mentions_spans]):\n",
        "                  true_count +=1  \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiIR2xpUSCLw",
        "outputId": "2f6513ea-49e9-40e5-a886-d31ef0010c6d"
      },
      "source": [
        "acc_male = evaluate_gender(data_gold, nlp, 'Male')\n",
        "acc_female = evaluate_gender(data_gold, nlp, 'Female')\n",
        "delta_g = acc_male - acc_female\n",
        "print(delta_g)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1336\n",
            "383\n",
            "0.039598348993918175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz09SKTDDmsM"
      },
      "source": [
        "# use this metric to calculate stereotype bias of the model\n",
        "def evaluate_stereotype(data, nlp, stereotype):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "  tp = 0 \n",
        "  tn = 0 \n",
        "  fp = 0 \n",
        "  fn = 0 \n",
        "  data_new = data.drop(data[(data['stereotype'] != stereotype)].index)\n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              if is_inside(row['profession_first_index'], main_span) and \\\n",
        "                      np.any([is_inside(row['g_first_index'], s) for s in mentions_spans]):\n",
        "                  true_count +=1  \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idcc1ZMzBAEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ab9e27-a2fe-4e6f-8069-63d7927582c9"
      },
      "source": [
        "acc_antistereo = evaluate_stereotype(data_gold, nlp, -1)\n",
        "acc_stereo = evaluate_stereotype(data_gold, nlp, 1)\n",
        "delta_s = acc_stereo - acc_antistereo\n",
        "print(delta_s)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n",
            "864\n",
            "-0.03687169312169314\n"
          ]
        }
      ]
    }
  ]
}