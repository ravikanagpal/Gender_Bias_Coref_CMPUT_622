{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClarknManning_neuralcoref.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igpDu_oHTNrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c32bf83-0d01-41c6-d6f2-3bc0aa0d4072"
      },
      "source": [
        "!git clone https://github.com/ravikanagpal/Gender_Bias_Coref_CMPUT_622"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Gender_Bias_Coref_CMPUT_622'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 74 (delta 19), reused 32 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDbhAe0TKuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839bc455-5767-4db4-93a4-7f52873b390d"
      },
      "source": [
        "!pip install -q neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 368 kB 11.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 48.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.0 MB/s \n",
            "\u001b[?25h    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3XfhlfXTRTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dfb1eb-fa4d-4de0-cc47-f2451f6fda0f"
      },
      "source": [
        "!pip install -q -U spacy==2.1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 27.7 MB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 25.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 32.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 323 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTo47VutTT43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96edb4bb-dbbd-4812-f745-b0b19d9c3619"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 12.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074431 sha256=f3d93eeafa0cf86ae73205c6a9a19234700352eea43654f774320ce2195124f8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8h03wpr6/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTSFCuDUTXC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bd4869-b4bb-474b-ce30-edbed70a702d"
      },
      "source": [
        "import json, random\n",
        "from tqdm.notebook import tqdm\n",
        "from urllib.parse import quote\n",
        "\n",
        "# Load your usual SpaCy model (one of SpaCy English models)\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add neural coref to SpaCy's pipe\n",
        "import neuralcoref\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40155833/40155833 [00:02<00:00, 19555785.95B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f2d6439d250>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj9zImVZgH-3"
      },
      "source": [
        "# parse each sentence and predict pronoun\n",
        "import pandas as pd\n",
        "\n",
        "data_gold = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/gold_BUG.csv\")\n",
        "data_full = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/full_BUG.csv\")\n",
        "data_balanced = pd.read_csv(\"/content/Gender_Bias_Coref_CMPUT_622/data/balanced_BUG.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeQmGGCSLwhj"
      },
      "source": [
        "# saving the results in the csv format\n",
        "def save_results(results, resultfile = \"/content/Gender_Bias_Coref_CMPUT_622/output/neuralcoref.csv\"):\n",
        "    column_names = [\"predicted gender\", \"sentence text\", \"profession\", \"gender\",\"stereotype\", \"predicted gender\", \"predicted mentions\", \"Prediction\"]\n",
        "    df = pd.DataFrame(results, columns=column_names)\n",
        "    # storing the results to csv file\n",
        "    df.to_csv(resultfile, index=False)\n",
        "    return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vFWVEXaqkBp"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGQj_6qJQz3N"
      },
      "source": [
        "# This function finds coreferences clusters and check its span corresponding to occupation and gender index to get model accuracy\n",
        "def evaluate(data, nlp):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "  records = []\n",
        "  for index, row in data.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              flag = False\n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  flag = True\n",
        "              records.append((row['predicted gender'], row['sentence_text'], row['profession'], row['g'], row['stereotype'], main, cluster.mentions, flag))\n",
        "  save_results(records)\n",
        "  print(total_count)            \n",
        "  return true_count/ total_count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCDk6KMRAhm",
        "outputId": "88a02110-07c6-4c3b-e1a9-773de196e4cf"
      },
      "source": [
        "# check model accuracy on gold dataset\n",
        "print(evaluate(data_gold, nlp))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719\n",
            "0.4816753926701571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3xtBviRq6h"
      },
      "source": [
        "#This function is used to calculate female vs male accuracy i.e. fairness metric delta-g\n",
        "def evaluate_gender(data, nlp, gender):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        "\n",
        "  data_new = data.drop(data[(data['predicted gender'] != gender)].index)    \n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              \n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  \n",
        "              \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiIR2xpUSCLw",
        "outputId": "e5e91c50-3213-4d16-e8a9-544008ca0ad6"
      },
      "source": [
        "acc_male = evaluate_gender(data_gold, nlp, 'Male')\n",
        "acc_female = evaluate_gender(data_gold, nlp, 'Female')\n",
        "delta_g = acc_male - acc_female\n",
        "print(delta_g)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1336\n",
            "383\n",
            "0.025134456934694627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz09SKTDDmsM"
      },
      "source": [
        "# use this metric to calculate stereotype bias of the model\n",
        "def evaluate_stereotype(data, nlp, stereotype):\n",
        "  total_count = 0\n",
        "  true_count = 0\n",
        " \n",
        "  data_new = data.drop(data[(data['stereotype'] != stereotype)].index)\n",
        "  for index, row in data_new.iterrows():\n",
        "      s = row['sentence_text']\n",
        "      if s:\n",
        "        if isinstance(s, str):\n",
        "          total_count += 1\n",
        "          doc = nlp(row['sentence_text'])\n",
        "          if doc._.has_coref:\n",
        "            for cluster in doc._.coref_clusters:\n",
        "              \n",
        "              main = cluster.main\n",
        "              main_span = main.start, main.end\n",
        "              mentions_spans = [(m.start, m.end) for m in cluster.mentions \\\n",
        "                                if (m.start, m.end) != main_span]\n",
        "              mentions = cluster.mentions\n",
        "              pronouns = [sp.text for sp in mentions]\n",
        "             \n",
        "              if (row['profession'] in main.text) and \\\n",
        "                    (np.any([row['g'] in sp for sp in pronouns])):\n",
        "                  true_count +=1  \n",
        "                  \n",
        "              \n",
        "  print(total_count)            \n",
        "  return true_count/ total_count\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idcc1ZMzBAEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f36653-b5c1-4f62-8de5-cb6788492d43"
      },
      "source": [
        "acc_antistereo = evaluate_stereotype(data_gold, nlp, -1)\n",
        "acc_stereo = evaluate_stereotype(data_gold, nlp, 1)\n",
        "delta_s = acc_stereo - acc_antistereo\n",
        "print(delta_s)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n",
            "864\n",
            "-0.04298941798941802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJKuvRTAc_tS",
        "outputId": "2f405cad-25f9-450b-eaa9-b019b851aab4"
      },
      "source": [
        "# evaluate model on balanced dataset\n",
        "print(evaluate(data_balanced, nlp))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25504\n",
            "0.4126411543287328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7n2Jt3-dPZ-",
        "outputId": "6d5cda01-db0b-42db-a229-3febaa13b309"
      },
      "source": [
        "# evaluate model on full dataset\n",
        "print(evaluate(data_full, nlp))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105687\n",
            "0.4525722179643665\n"
          ]
        }
      ]
    }
  ]
}